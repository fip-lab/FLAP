/////////////////////////////////////////////////////////////////////////////////
//                                                                             //
//                                                                             //
// RDDL MDP version of Wildlife Preserve instance #13 for IPC 2018 by Fei Fang //
// (feifang [at] cmu.edu), Thanh Hong Nguyen (thanhhng [at] umich.edu) and     //
// Thomas Keller (tho.keller [at] unibas.ch), based on the papers "When        //
// Security Games Go Green: Designing Defender Strategies to Prevent Poaching  //
// and Illegal Fishing" by Fei Fang, Peter Stone and Milind Tambe (IJCAI 2015) //
// and "Analyzing the Effectiveness of Adversary Modeling in Security Games"   //
// by Thanh H. Nguyen, Rong Yang, Amos Azaria, Sarit Kraus and Milind Tambe    //
// (AAAI 2013).                                                                //
//                                                                             //
//                                                                             //
/////////////////////////////////////////////////////////////////////////////////

instance wildlife-preserve_inst_mdp__13 {
    domain = wildlife-preserve_13_mdp;

    objects {
        ranger  : { r1, r2 };
        poacher : { p1, p2 };
    };

    non-fluents {
        DEFENDER-REWARD_a1 = 5.42;
        DEFENDER-PENALTY_a1 = -7.73;
        DEFENDER-REWARD_a2 = 7.43;
        DEFENDER-PENALTY_a2 = -1.73;
        DEFENDER-REWARD_a3 = 1.82;
        DEFENDER-PENALTY_a3 = -4.12;
        DEFENDER-REWARD_a4 = 1.56;
        DEFENDER-PENALTY_a4 = -1.67;
        DEFENDER-REWARD_a5 = 0.70;
        DEFENDER-PENALTY_a5 = -7.87;
        DEFENDER-REWARD_a6 = 3.32;
        DEFENDER-PENALTY_a6 = -5.27;
        DEFENDER-REWARD_a7 = 3.72;
        DEFENDER-PENALTY_a7 = -1.58;
        DEFENDER-REWARD_a8 = 5.87;
        DEFENDER-PENALTY_a8 = -1.21;
        DEFENDER-REWARD_a9 = 0.71;
        DEFENDER-PENALTY_a9 = -6.61;
        DEFENDER-REWARD_a10 = 3.33;
        DEFENDER-PENALTY_a10 = -3.60;

        // correlation between attacker reward and defender penalty as well as
        // attacker penalty and defender reward is 1.00 for all poachers and all areas

        // weights for poacher p1 are: w1 = -15.02, w2 = 0.64, w3 = 0.45
        // reward for poacher p1 in area @a1 is: 7.73
        // penalty for poacher p1 in area @a1 is: -5.42
        // reward for poacher p1 in area @a2 is: 1.73
        // penalty for poacher p1 in area @a2 is: -7.43
        // reward for poacher p1 in area @a3 is: 4.12
        // penalty for poacher p1 in area @a3 is: -1.82
        // reward for poacher p1 in area @a4 is: 1.67
        // penalty for poacher p1 in area @a4 is: -1.56
        // reward for poacher p1 in area @a5 is: 7.87
        // penalty for poacher p1 in area @a5 is: -0.70
        // reward for poacher p1 in area @a6 is: 5.27
        // penalty for poacher p1 in area @a6 is: -3.32
        // reward for poacher p1 in area @a7 is: 1.58
        // penalty for poacher p1 in area @a7 is: -3.72
        // reward for poacher p1 in area @a8 is: 1.21
        // penalty for poacher p1 in area @a8 is: -5.87
        // reward for poacher p1 in area @a9 is: 6.61
        // penalty for poacher p1 in area @a9 is: -0.71
        // reward for poacher p1 in area @a10 is: 3.60
        // penalty for poacher p1 in area @a10 is: -3.33

        // weights for poacher p2 are: w1 = -10.99, w2 = 0.86, w3 = 0.44
        // reward for poacher p2 in area @a1 is: 7.73
        // penalty for poacher p2 in area @a1 is: -5.42
        // reward for poacher p2 in area @a2 is: 1.73
        // penalty for poacher p2 in area @a2 is: -7.43
        // reward for poacher p2 in area @a3 is: 4.12
        // penalty for poacher p2 in area @a3 is: -1.82
        // reward for poacher p2 in area @a4 is: 1.67
        // penalty for poacher p2 in area @a4 is: -1.56
        // reward for poacher p2 in area @a5 is: 7.87
        // penalty for poacher p2 in area @a5 is: -0.70
        // reward for poacher p2 in area @a6 is: 5.27
        // penalty for poacher p2 in area @a6 is: -3.32
        // reward for poacher p2 in area @a7 is: 1.58
        // penalty for poacher p2 in area @a7 is: -3.72
        // reward for poacher p2 in area @a8 is: 1.21
        // penalty for poacher p2 in area @a8 is: -5.87
        // reward for poacher p2 in area @a9 is: 6.61
        // penalty for poacher p2 in area @a9 is: -0.71
        // reward for poacher p2 in area @a10 is: 3.60
        // penalty for poacher p2 in area @a10 is: -3.33

        ATTACK-WEIGHT_0_a1(p1) = 12.93501;
        ATTACK-WEIGHT_1_a1(p1) = 0.00709;
        ATTACK-WEIGHT_2_a1(p1) = 0.00000;
        ATTACK-WEIGHT_0_a2(p1) = 0.11112;
        ATTACK-WEIGHT_1_a2(p1) = 0.00006;
        ATTACK-WEIGHT_2_a2(p1) = 0.00000;
        ATTACK-WEIGHT_0_a3(p1) = 6.30054;
        ATTACK-WEIGHT_1_a3(p1) = 0.00345;
        ATTACK-WEIGHT_2_a3(p1) = 0.00000;
        ATTACK-WEIGHT_0_a4(p1) = 1.46185;
        ATTACK-WEIGHT_1_a4(p1) = 0.00080;
        ATTACK-WEIGHT_2_a4(p1) = 0.00000;
        ATTACK-WEIGHT_0_a5(p1) = 115.94394;
        ATTACK-WEIGHT_1_a5(p1) = 0.06358;
        ATTACK-WEIGHT_2_a5(p1) = 0.00003;
        ATTACK-WEIGHT_0_a6(p1) = 6.76938;
        ATTACK-WEIGHT_1_a6(p1) = 0.00371;
        ATTACK-WEIGHT_2_a6(p1) = 0.00000;
        ATTACK-WEIGHT_0_a7(p1) = 0.52695;
        ATTACK-WEIGHT_1_a7(p1) = 0.00029;
        ATTACK-WEIGHT_2_a7(p1) = 0.00000;
        ATTACK-WEIGHT_0_a8(p1) = 0.15934;
        ATTACK-WEIGHT_1_a8(p1) = 0.00009;
        ATTACK-WEIGHT_2_a8(p1) = 0.00000;
        ATTACK-WEIGHT_0_a9(p1) = 51.30232;
        ATTACK-WEIGHT_1_a9(p1) = 0.02813;
        ATTACK-WEIGHT_2_a9(p1) = 0.00002;
        ATTACK-WEIGHT_0_a10(p1) = 2.30060;
        ATTACK-WEIGHT_1_a10(p1) = 0.00126;
        ATTACK-WEIGHT_2_a10(p1) = 0.00000;
        ATTACK-WEIGHT_0_a1(p2) = 69.68216;
        ATTACK-WEIGHT_1_a1(p2) = 0.28600;
        ATTACK-WEIGHT_2_a1(p2) = 0.00117;
        ATTACK-WEIGHT_0_a2(p2) = 0.16467;
        ATTACK-WEIGHT_1_a2(p2) = 0.00068;
        ATTACK-WEIGHT_2_a2(p2) = 0.00000;
        ATTACK-WEIGHT_0_a3(p2) = 15.41542;
        ATTACK-WEIGHT_1_a3(p2) = 0.06327;
        ATTACK-WEIGHT_2_a3(p2) = 0.00026;
        ATTACK-WEIGHT_0_a4(p2) = 2.10548;
        ATTACK-WEIGHT_1_a4(p2) = 0.00864;
        ATTACK-WEIGHT_2_a4(p2) = 0.00004;
        ATTACK-WEIGHT_0_a5(p2) = 635.80142;
        ATTACK-WEIGHT_1_a5(p2) = 2.60957;
        ATTACK-WEIGHT_2_a5(p2) = 0.01071;
        ATTACK-WEIGHT_0_a6(p2) = 21.31701;
        ATTACK-WEIGHT_1_a6(p2) = 0.08749;
        ATTACK-WEIGHT_2_a6(p2) = 0.00036;
        ATTACK-WEIGHT_0_a7(p2) = 0.74861;
        ATTACK-WEIGHT_1_a7(p2) = 0.00307;
        ATTACK-WEIGHT_2_a7(p2) = 0.00001;
        ATTACK-WEIGHT_0_a8(p2) = 0.21016;
        ATTACK-WEIGHT_1_a8(p2) = 0.00086;
        ATTACK-WEIGHT_2_a8(p2) = 0.00000;
        ATTACK-WEIGHT_0_a9(p2) = 214.30069;
        ATTACK-WEIGHT_1_a9(p2) = 0.87957;
        ATTACK-WEIGHT_2_a9(p2) = 0.00361;
        ATTACK-WEIGHT_0_a10(p2) = 5.05092;
        ATTACK-WEIGHT_1_a10(p2) = 0.02073;
        ATTACK-WEIGHT_2_a10(p2) = 0.00009;

        POACHER-REMEMBERS_1(p1);
        POACHER-REMEMBERS_2(p1);
        POACHER-REMEMBERS_1(p2);
        POACHER-REMEMBERS_2(p2);

    };

    init-state {
        ~was-defended_1_a1;
    };

    horizon = 30;

    discount = 1.0;
}